import streamlit as st
import streamlit.components.v1 as components

st.set_page_config(page_title="Scam Detector", page_icon="üïµÔ∏è‚Äç‚ôÇÔ∏è", layout="wide")

import nemo.collections.asr as nemo_asr
import torch
import librosa
import soundfile as sf
import os
import tempfile
import json
import google.generativeai as genai
from google.generativeai.types import GenerationConfig
from st_audiorec import st_audiorec
from langchain_chroma import Chroma
from langchain_huggingface import HuggingFaceEmbeddings
from dotenv import load_dotenv
import requests

load_dotenv()

CHROMA_PATH = "./chroma_db_thairath"
BACKEND_API_URL = "http://localhost:8000/notify"
DEFAULT_TARGET_GROUP_ID = "YOUR_TARGET_GROUP_ID_HERE"

def init_session_state():
    # ‡∏≠‡πà‡∏≤‡∏ô‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å URL (st.query_params ‡πÅ‡∏ö‡∏ö‡πÉ‡∏´‡∏°‡πà)
    query_params = st.query_params
    
    url_user_id = query_params.get("line_user_id", None)
    url_group_id = query_params.get("target_group_id", None)
    
    # 1. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ User ID
    if url_user_id:
        st.session_state['line_user_id'] = url_user_id
    
    # 2. ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ Group ID (‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏°‡∏≤‡∏Å: ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÉ‡∏ô URL ‡πÉ‡∏´‡πâ‡∏ó‡∏±‡∏ö‡πÉ‡∏ô Session ‡πÄ‡∏•‡∏¢)
    if url_group_id:
        st.session_state['target_group_id'] = url_group_id
    
    # ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ô Session ‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ ‡πÉ‡∏´‡πâ‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á
    if 'target_group_id' not in st.session_state:
        st.session_state['target_group_id'] = ""
        
    if 'line_user_id' not in st.session_state:
        st.session_state['line_user_id'] = ""

# ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÇ‡∏´‡∏•‡∏î‡∏´‡∏ô‡πâ‡∏≤
init_session_state()

# ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤‡∏à‡∏≤‡∏Å Session ‡∏°‡∏≤‡πÉ‡∏ä‡πâ (‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏´‡∏•‡∏±‡∏Å‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÄ‡∏≠‡∏≤‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏ó‡∏±‡πâ‡∏á‡πÅ‡∏≠‡∏õ)
user_id = st.session_state['line_user_id']
target_group_id = st.session_state['target_group_id']
display_name = "User" # Default

# --- 3. Sidebar Setup ---
st.sidebar.header("üë§ ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠")

if user_id:
    st.sidebar.success(f"‚úÖ User ID: ...{user_id[-4:]}")
else:
    st.sidebar.warning("‚ö†Ô∏è Guest Mode (‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ Login)")

if target_group_id:
    st.sidebar.success(f"‚úÖ Group ID: ...{target_group_id[-4:]}")
    st.sidebar.caption(f"Full ID: {target_group_id}") # ‡πÅ‡∏™‡∏î‡∏á‡πÄ‡∏ï‡πá‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠ debug
else:
    st.sidebar.error("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö Group ID")
    st.sidebar.info("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÄ‡∏Ç‡πâ‡∏≤‡∏ú‡πà‡∏≤‡∏ô‡∏•‡∏¥‡∏á‡∏Å‡πå‡∏à‡∏≤‡∏Å LINE Bot ‡πÉ‡∏ô‡∏Å‡∏•‡∏∏‡πà‡∏°")
    
    # ‡πÉ‡∏´‡πâ‡∏Å‡∏£‡∏≠‡∏Å‡πÄ‡∏≠‡∏á‡πÑ‡∏î‡πâ‡∏Å‡∏£‡∏ì‡∏µ‡∏â‡∏∏‡∏Å‡πÄ‡∏â‡∏¥‡∏ô
    target_group_id = st.sidebar.text_input("‡πÉ‡∏™‡πà Group ID ‡πÄ‡∏≠‡∏á (‡∏ñ‡πâ‡∏≤‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô):", value=st.session_state['target_group_id'])
    # ‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤ session ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏û‡∏¥‡∏°‡∏û‡πå‡πÅ‡∏Å‡πâ
    if target_group_id:
        st.session_state['target_group_id'] = target_group_id

st.sidebar.divider()
use_rag_feature = st.sidebar.toggle("üìö Use RAG", value=True)


@st.cache_resource
def load_rag_system():
    """Load Embedding model and Vector DB"""
    try:
        embeddings = HuggingFaceEmbeddings(
            model_name="BAAI/bge-m3",
            model_kwargs={'device': 'cpu'},
            encode_kwargs={'normalize_embeddings': True}
        )
        if os.path.exists(CHROMA_PATH):
            db = Chroma(persist_directory=CHROMA_PATH, embedding_function=embeddings, collection_name="thairath_news")
            return db
        return None
    except Exception as e:
        st.error(f"Failed to load Knowledge Base: {e}")
        return None

vector_db = load_rag_system()
# --- ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Gemini API ---
@st.cache_resource
def setup_gemini_client():
    """
    ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö API key
    """
    api_key = None
    try:
        api_key = os.getenv("GOOGLE_API_KEY")
    except FileNotFoundError:
        st.sidebar.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå .env")
    except KeyError:
        st.sidebar.warning("‡πÑ‡∏°‡πà‡∏û‡∏ö GOOGLE_API_KEY ‡πÉ‡∏ô .env")

    if not api_key:
        api_key = st.sidebar.text_input("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏õ‡πâ‡∏≠‡∏ô Gemini API Key ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì:", type="password", key="api_key_input")

    if not api_key:
        st.error("‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ Gemini API Key ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
        st.stop()
    
    try:
        genai.configure(api_key=api_key)
        return genai
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Gemini: {e}")
        st.stop()

@st.cache_resource
def load_asr_model():
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    model = nemo_asr.models.ASRModel.from_pretrained(
        model_name="scb10x/typhoon-asr-realtime",
        map_location=device
    )
    return model, device

# --- Setup ---
genai_client = setup_gemini_client()

asr_model_status = st.sidebar.info("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÇ‡∏´‡∏•‡∏î‡πÇ‡∏°‡πÄ‡∏î‡∏• Typhoon ASR...")
asr_model, device = load_asr_model()
asr_model_status.success(f"‡πÇ‡∏°‡πÄ‡∏î‡∏• ASR ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô! ({device.upper()})")

def prepare_audio(input_path, output_path, target_sr=16000):
    """
    ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Typhoon ASR (‡∏î‡∏±‡∏î‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å‡πÇ‡∏Ñ‡πâ‡∏î‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì)
    """
    try:
        # Load (‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö MP3/WAV)
        y, sr = librosa.load(input_path, sr=None)
        
        if sr != target_sr:
            y = librosa.resample(y, orig_sr=sr, target_sr=target_sr)
        
        # Normalize
        y = y / max(abs(y))
        
        # Save ‡πÄ‡∏õ‡πá‡∏ô WAV
        sf.write(output_path, y, target_sr)
        return output_path
    
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡∏£‡∏∞‡∏´‡∏ß‡πà‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á: {e}")
        return None

def run_transcription(asr_model, uploaded_file):
    """
    ‡∏£‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î (MP3/WAV) ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏• ‡πÅ‡∏•‡∏∞‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á
    """
    file_suffix = os.path.splitext(uploaded_file.name)[-1]
    
    with tempfile.NamedTemporaryFile(delete=False, suffix=file_suffix) as tmp_in:
        tmp_in.write(uploaded_file.getvalue())
        input_audio_path = tmp_in.name

    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_out:
        output_wav_path = tmp_out.name

    try:
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á..."):
            processed_wav = prepare_audio(input_audio_path, output_wav_path)
        
        if processed_wav:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• Typhoon..."):
                transcriptions = asr_model.transcribe(audio=[processed_wav])
                if transcriptions:
                    return transcriptions[0].text
                else:
                    return "[‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ]"
        else:
            return "[‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á]"

    finally:
        if os.path.exists(input_audio_path):
            os.remove(input_audio_path)
        if os.path.exists(output_wav_path):
            os.remove(output_wav_path)

# --- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÉ‡∏´‡∏°‡πà‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô ---
def run_transcription_from_mic(asr_model, audio_bytes):
    """
    ‡∏£‡∏±‡∏ö audio bytes (WAV) ‡∏à‡∏≤‡∏Å st_audiorec, ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•, ‡πÅ‡∏•‡∏∞‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á
    """
    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_in:
        tmp_in.write(audio_bytes)
        input_wav_path = tmp_in.name

    with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_out:
        output_wav_path = tmp_out.name

    try:
        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡∏™‡∏ô‡∏ó‡∏ô‡∏≤..."):
            processed_wav = prepare_audio(input_wav_path, output_wav_path)
        
        if processed_wav:
            with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏• Typhoon..."):
                transcriptions = asr_model.transcribe(audio=[processed_wav])
                if transcriptions:
                    return transcriptions[0].text
                else:
                    return "[‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏î‡πâ]"
        else:
            return "[‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á]"

    finally:
        if os.path.exists(input_wav_path):
            os.remove(input_wav_path)
        if os.path.exists(output_wav_path):
            os.remove(output_wav_path)
            

@st.cache_data(show_spinner=False)
def analyze_scam_with_llm(_genai_client, text_to_analyze, use_rag=True):
    """
    ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å Gemini API ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Scammer ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    """

    retrieved_context = ""
    references = []
    
    if use_rag and vector_db:
        docs = vector_db.similarity_search(text_to_analyze, k=3)
        if docs:
            retrieved_context = "\n".join([f"- {d.page_content}" for d in docs])
            references = [d.metadata.get('title', '‡πÑ‡∏°‡πà‡∏£‡∏∞‡∏ö‡∏∏‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤') for d in docs]
 
    ref_section = ""
    if use_rag:
        ref_section = f"""
        [‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏à‡∏≤‡∏Å‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡πà‡∏≤‡∏ß/‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏†‡∏±‡∏¢]:
        {retrieved_context if retrieved_context else "‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ô‡πÉ‡∏ô‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"}
        
        ‡∏Ñ‡∏≥‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°: ‡∏´‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô [‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á] ‡∏™‡∏≠‡∏î‡∏Ñ‡∏•‡πâ‡∏≠‡∏á‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏∏‡πÉ‡∏ô‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏î‡πâ‡∏ß‡∏¢
        """

    system_prompt = f"""
    ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç‡∏î‡πâ‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏ó‡∏≤‡∏á‡πÑ‡∏ã‡πÄ‡∏ö‡∏≠‡∏£‡πå‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏´‡∏•‡∏≠‡∏Å‡∏•‡∏ß‡∏á (Scam)
    ‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏∑‡∏≠‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö ‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏à‡∏â‡∏≤‡∏ä‡∏µ‡∏û‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
    
    {ref_section}
    
    ‡πÇ‡∏õ‡∏£‡∏î‡∏ï‡∏≠‡∏ö‡∏Å‡∏•‡∏±‡∏ö‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢ ‡πÅ‡∏•‡∏∞‡πÉ‡∏ä‡πâ‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á JSON ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡πÄ‡∏ó‡πà‡∏≤‡∏ô‡∏±‡πâ‡∏ô
    ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÇ‡∏î‡∏¢‡∏û‡∏¥‡∏à‡∏≤‡∏£‡∏ì‡∏≤‡∏õ‡∏±‡∏à‡∏à‡∏±‡∏¢‡∏ï‡πà‡∏≤‡∏á‡πÜ ‡πÄ‡∏ä‡πà‡∏ô:
    - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πà‡∏á‡∏î‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥ (‡πÄ‡∏ä‡πà‡∏ô "‡∏ï‡πâ‡∏≠‡∏á‡∏ó‡∏≥‡∏ó‡∏±‡∏ô‡∏ó‡∏µ", "‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏£‡∏∞‡∏á‡∏±‡∏ö")
    - ‡∏Å‡∏≤‡∏£‡∏Ç‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ï‡∏±‡∏ß (‡πÄ‡∏ä‡πà‡∏ô ‡∏£‡∏´‡∏±‡∏™‡∏ú‡πà‡∏≤‡∏ô, ‡πÄ‡∏•‡∏Ç‡∏ö‡∏±‡∏ï‡∏£‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏ä‡∏ô, ‡∏£‡∏´‡∏±‡∏™ OTP)
    - ‡∏Å‡∏≤‡∏£‡∏≠‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏à‡πâ‡∏≤‡∏´‡∏ô‡πâ‡∏≤‡∏ó‡∏µ‡πà (‡πÄ‡∏ä‡πà‡∏ô ‡∏ï‡∏≥‡∏£‡∏ß‡∏à, ‡∏ò‡∏ô‡∏≤‡∏Ñ‡∏≤‡∏£, ‡∏Å‡∏£‡∏°‡∏™‡∏£‡∏£‡∏û‡∏≤‡∏Å‡∏£)
    - ‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏ô‡∏≠‡∏ú‡∏•‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏ó‡∏µ‡πà‡∏ô‡πà‡∏≤‡∏™‡∏á‡∏™‡∏±‡∏¢ (‡πÄ‡∏ä‡πà‡∏ô ‡∏ñ‡∏π‡∏Å‡∏£‡∏≤‡∏á‡∏ß‡∏±‡∏•, ‡πÑ‡∏î‡πâ‡πÄ‡∏á‡∏¥‡∏ô‡∏Ñ‡∏∑‡∏ô)
    - ‡∏Å‡∏≤‡∏£‡∏Ç‡πà‡∏°‡∏Ç‡∏π‡πà (‡πÄ‡∏ä‡πà‡∏ô "‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏î‡∏≥‡πÄ‡∏ô‡∏¥‡∏ô‡∏Ñ‡∏î‡∏µ")
    """

    json_schema = {
        "type": "OBJECT",
        "properties": {
            "verdict": {
                "type": "STRING",
                "description": "‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô (‡πÄ‡∏ä‡πà‡∏ô '‡∏°‡∏µ‡πÇ‡∏≠‡∏Å‡∏≤‡∏™‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏à‡∏â‡∏≤‡∏ä‡∏µ‡∏û‡∏™‡∏π‡∏á', '‡πÑ‡∏°‡πà‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏¥‡∏à‡∏â‡∏≤‡∏ä‡∏µ‡∏û', '‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠')"
            },
            "confidence": {
                "type": "STRING",
                "description": "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à (‡πÄ‡∏ä‡πà‡∏ô '‡∏™‡∏π‡∏á', '‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á', '‡∏ï‡πà‡∏≥')"
            },
            "reasoning": {
                "type": "ARRAY",
                "items": {"type": "STRING"},
                "description": "‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡πÜ"
            },
            "warning_signs": {
                "type": "ARRAY",
                "items": {"type": "STRING"},
                "description": "‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ)"
            }
        },
        "required": ["verdict", "confidence", "reasoning"]
    }

    # 3. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ GenerationConfig
    generation_config = GenerationConfig(
        response_mime_type="application/json",
        response_schema=json_schema
    )

    # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÇ‡∏°‡πÄ‡∏î‡∏•
    model = genai.GenerativeModel(
        model_name="gemini-2.5-flash",
        system_instruction=system_prompt,
        generation_config=generation_config
    )

    # 5. ‡∏™‡∏£‡πâ‡∏≤‡∏á Prompt
    prompt = f"‡πÇ‡∏õ‡∏£‡∏î‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ô‡∏µ‡πâ: \"{text_to_analyze}\""

    # 6. ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API
    try:
        response = model.generate_content(prompt)
        # Parse JSON
        result = json.loads(response.text)
        result['references'] = references
        return result
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å LLM: {e}")
        if "response" in locals():
            st.error(f"Response ‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö: {response.parts}")
        return None

def send_alert_to_line(message, result, user_name, target_id):
    """
    ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏õ‡∏¢‡∏±‡∏á FastAPI service ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô Line
    ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤ user_name ‡πÅ‡∏•‡∏∞ target_id ‡πÄ‡∏Ç‡πâ‡∏≤‡∏°‡∏≤‡πÇ‡∏î‡∏¢‡∏ï‡∏£‡∏á‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ß‡∏£‡πå
    """
    # Fallback: ‡∏ñ‡πâ‡∏≤ target_id ‡∏ó‡∏µ‡πà‡∏™‡πà‡∏á‡∏°‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡πà‡∏≤‡∏ß‡πà‡∏≤‡∏á ‡πÉ‡∏´‡πâ‡∏•‡∏≠‡∏á‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å Session ‡∏≠‡∏µ‡∏Å‡∏£‡∏≠‡∏ö
    if not target_id:
        target_id = st.session_state.get('target_group_id')
    
    # ‡∏î‡∏∂‡∏á User ID (Reporter) ‡∏à‡∏≤‡∏Å Session ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡πÄ‡∏õ‡πá‡∏ô Fallback
    reporter_id = st.session_state.get('line_user_id')

    payload = {
        "message": message,
        "fraud_details": result,
        "user_name": user_name if user_name else "Group Member",
        "target_id": target_id,
        "reporter_id": reporter_id 
    }

    try:
        # üü¢ ‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç 1: ‡πÉ‡∏ä‡πâ‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£ BACKEND_API_URL ‡πÉ‡∏´‡πâ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏Å‡∏≤‡∏®‡πÑ‡∏ß‡πâ‡∏Ç‡πâ‡∏≤‡∏á‡∏ö‡∏ô
        response = requests.post(BACKEND_API_URL, json=payload)
            
        if response.status_code == 200:
            st.toast("‚úÖ ‡∏™‡πà‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÑ‡∏õ‡∏¢‡∏±‡∏á Group Line ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡πÅ‡∏•‡πâ‡∏ß!", icon="üì®")
        else:
            st.toast("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏™‡πà‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô Line ‡πÑ‡∏î‡πâ", icon="‚ùå")
            # ‡πÅ‡∏™‡∏î‡∏á Error ‡∏à‡∏≤‡∏Å Server ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏π‡πâ‡∏™‡∏≤‡πÄ‡∏´‡∏ï‡∏∏
            st.error(f"Server Error ({response.status_code}): {response.text}")
            
    except Exception as e:
        st.error(f"Connection Error: {e}")

def display_analysis_results(result, analyzed_text=None):
    """
    ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏™‡∏ß‡∏¢‡∏á‡∏≤‡∏°
    """
    st.subheader("‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:")
    
    verdict = result.get("verdict", "‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö‡∏ú‡∏•")
    confidence = result.get("confidence", "‡πÑ‡∏°‡πà‡∏ó‡∏£‡∏≤‡∏ö")

    current_group_id = st.session_state.get('target_group_id')
    
    if "‡∏™‡∏π‡∏á" in verdict or "High" in verdict:
        st.error(f"üö® **{verdict}** (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {confidence})")
        
        # *** AUTO ALERT ***
        if current_group_id and DEFAULT_TARGET_GROUP_ID != "Cxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx":
             with st.spinner("üöÄ ‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á! ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô‡πÄ‡∏Ç‡πâ‡∏≤‡∏Å‡∏•‡∏∏‡πà‡∏° LINE..."):
                send_alert_to_line(analyzed_text, result, display_name, current_group_id)
        elif current_group_id:
             st.warning("‚ö†Ô∏è ‡∏û‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏™‡∏µ‡πà‡∏¢‡∏á‡∏™‡∏π‡∏á ‡πÅ‡∏ï‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Group ID ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á ‡∏à‡∏∂‡∏á‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏™‡πà‡∏á‡πÅ‡∏à‡πâ‡∏á‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô")
                
    elif "‡∏õ‡∏≤‡∏ô‡∏Å‡∏•‡∏≤‡∏á" in verdict:
        st.warning(f"‚ö†Ô∏è **{verdict}** (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {confidence})")
    else:
        st.success(f"‚úÖ **{verdict}** (‡∏Ñ‡∏ß‡∏≤‡∏°‡∏°‡∏±‡πà‡∏ô‡πÉ‡∏à: {confidence})")

    # ‡πÅ‡∏™‡∏î‡∏á‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î
    st.markdown("**‡πÄ‡∏´‡∏ï‡∏∏‡∏ú‡∏•:**")
    for r in result.get("reasoning", []):
        st.markdown(f"- {r}")
        
    if result.get("warning_signs"):
        st.markdown("**‡∏™‡∏±‡∏ç‡∏ç‡∏≤‡∏ì‡πÄ‡∏ï‡∏∑‡∏≠‡∏ô:**")
        for s in result.get("warning_signs", []):
            st.markdown(f"- {s}")

# --- ‡∏´‡∏ô‡πâ‡∏≤‡∏à‡∏≠‡∏´‡∏•‡∏±‡∏Å Streamlit ---

st.title("üïµÔ∏è‚Äç‚ôÇÔ∏è ‡πÅ‡∏≠‡∏õ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏°‡∏¥‡∏à‡∏â‡∏≤‡∏ä‡∏µ‡∏û (Scam Detector)")
st.caption("‡∏Ç‡∏±‡∏ö‡πÄ‡∏Ñ‡∏•‡∏∑‡πà‡∏≠‡∏ô‡∏î‡πâ‡∏ß‡∏¢ Typhoon ASR + Gemini LLM")

# --- UI Tabs ---
tab1, tab2, tab3 = st.tabs(["üìÅ ‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á", "‚úèÔ∏è ‡∏õ‡πâ‡∏≠‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°", "üéôÔ∏è ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏™‡∏î‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô"])

with tab1:
    st.header("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á")
    uploaded_file = st.file_uploader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏™‡∏µ‡∏¢‡∏á .mp3 ‡∏´‡∏£‡∏∑‡∏≠ .wav", type=["mp3", "wav"])
    
    analyze_audio_button = st.button("‡∏ñ‡∏≠‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå", key="analyze_audio")

    if analyze_audio_button and uploaded_file:
        transcript = run_transcription(asr_model, uploaded_file)
        
        if transcript and not transcript.startswith("["):
            st.info(f"**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏≠‡∏î‡πÑ‡∏î‡πâ:**\n\n{transcript}")
            st.divider()
            

            with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå... (RAG: {'ON' if use_rag_feature else 'OFF'})"):
                analysis_result = analyze_scam_with_llm(genai_client, transcript, use_rag=use_rag_feature)
            
            if analysis_result:
                display_analysis_results(analysis_result, transcript)
        else:
            st.error(transcript) 

with tab2:
    st.header("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")
    text_input = st.text_area("‡∏õ‡πâ‡∏≠‡∏ô‡∏ö‡∏ó‡∏™‡∏ô‡∏ó‡∏ô‡∏≤‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå:", height=200, key="text_input_area")
    
    analyze_text_button = st.button("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°", key="analyze_text")

    if analyze_text_button and text_input:
        with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå... (RAG: {'ON' if use_rag_feature else 'OFF'})"):
            analysis_result = analyze_scam_with_llm(genai_client, text_input, use_rag=use_rag_feature)
        
        if analysis_result:
            display_analysis_results(analysis_result, text_input)

with tab3:
    st.header("‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÑ‡∏°‡πÇ‡∏Ñ‡∏£‡πÇ‡∏ü‡∏ô")
    st.write("‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏π‡∏î ‡πÅ‡∏•‡∏∞‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏û‡∏π‡∏î‡∏à‡∏ö‡∏Ñ‡∏£‡∏±‡∏ö")
    
    # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å component ‡∏≠‡∏±‡∏î‡πÄ‡∏™‡∏µ‡∏¢‡∏á
    wav_audio_data = st_audiorec()

    if wav_audio_data is not None:
        
        transcript = run_transcription_from_mic(asr_model, wav_audio_data)
        
        if transcript and not transcript.startswith("["):
            st.info(f"**‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ñ‡∏≠‡∏î‡πÑ‡∏î‡πâ:**\n\n{transcript}")
            st.divider()
            
            with st.spinner(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÉ‡∏´‡πâ LLM ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå... (RAG: {'ON' if use_rag_feature else 'OFF'})"):
                analysis_result = analyze_scam_with_llm(genai_client, transcript, use_rag=use_rag_feature)
            
            if analysis_result:
                display_analysis_results(analysis_result, transcript)
        else:
            st.error(transcript)